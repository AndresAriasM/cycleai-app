from fastapi import FastAPI, HTTPException
from fastapi.middleware.cors import CORSMiddleware  # âœ… UbicaciÃ³n correcta
from pydantic import BaseModel
from typing import List
import requests
import re
from datetime import datetime
import os
from dotenv import load_dotenv

load_dotenv()

app = FastAPI()

app.add_middleware(
    CORSMiddleware,
    allow_origins=["http://localhost:5174"], # âœ… Puerto correcto
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

class SearchTerm(BaseModel):
    value: str
    operator: str = "AND"
    exact_match: bool = False

class HypeCycleRequest(BaseModel):
    search_terms: List[SearchTerm]
    min_year: int = 2015

class HypeCycleResponse(BaseModel):
    success: bool
    phase: str
    confidence: float
    total_mentions: int
    insights: List[str]
    chart_data: dict

def build_google_query(topics, min_year=None):
    """Construye query de bÃºsqueda"""
    if not topics:
        return ""
    
    parts = []
    for i, topic in enumerate(topics):
        value = topic.value.strip()
        if not value:
            continue
            
        if topic.exact_match:
            term = f'"{value}"'
        else:
            term = value
        
        parts.append(term)
        
        # AÃ±adir operador si no es el Ãºltimo
        if i < len(topics) - 1:
            parts.append(f" {topic.operator} ")
    
    query = "".join(parts)
    
    if min_year:
        query += f" after:{min_year}"
    
    return query

def perform_news_search(query, serp_api_key):
    """BÃºsqueda bÃ¡sica con SerpAPI"""
    try:
        url = "https://serpapi.com/search"
        params = {
            "api_key": serp_api_key,
            "q": query,
            "tbm": "nws",
            "num": 100,
            "gl": "us",
            "hl": "en"
        }
        
        response = requests.get(url, params=params)
        response.raise_for_status()
        data = response.json()
        
        results = []
        for item in data.get("news_results", []):
            # Extraer aÃ±o de la fecha
            year = extract_year(item.get("date", ""))
            
            results.append({
                "title": item.get("title", ""),
                "snippet": item.get("snippet", ""),
                "date": item.get("date", ""),
                "year": year,
                "source": item.get("source", ""),
                "sentiment": 0.1  # Placeholder - en MVP no calculamos sentiment real
            })
        
        return True, results
        
    except Exception as e:
        print(f"Error in search: {str(e)}")  # Debug
        return False, str(e)

def extract_year(date_str):
    """Extrae aÃ±o de string de fecha"""
    if not date_str:
        return datetime.now().year
    
    # Buscar aÃ±o en el string
    year_match = re.search(r'20\d{2}', date_str)
    if year_match:
        return int(year_match.group())
    
    return datetime.now().year

def analyze_hype_cycle(news_results):
    """AnÃ¡lisis bÃ¡sico del Hype Cycle"""
    if not news_results:
        return None
    
    # Agrupar por aÃ±o y contar menciones
    yearly_mentions = {}
    for result in news_results:
        year = result["year"]
        if year not in yearly_mentions:
            yearly_mentions[year] = 0
        yearly_mentions[year] += 1
    
    # Determinar fase bÃ¡sica
    total_mentions = len(news_results)
    recent_years = [year for year in yearly_mentions.keys() if year >= 2020]
    recent_mentions = sum(yearly_mentions.get(year, 0) for year in recent_years)
    
    # LÃ³gica simple para determinar fase
    if total_mentions < 20:
        phase = "Pre-Innovation Trigger"
        confidence = 0.4
    elif recent_mentions > total_mentions * 0.6:
        if total_mentions > 100:
            phase = "Peak of Inflated Expectations"
            confidence = 0.8
        else:
            phase = "Innovation Trigger"
            confidence = 0.7
    elif recent_mentions < total_mentions * 0.3:
        phase = "Trough of Disillusionment"
        confidence = 0.6
    else:
        phase = "Slope of Enlightenment"
        confidence = 0.5
    
    # Datos para el grÃ¡fico
    chart_data = {
        "yearly_mentions": yearly_mentions,
        "phase_position": get_phase_position(phase),
        "total_mentions": total_mentions
    }
    
    return {
        "phase": phase,
        "confidence": confidence,
        "total_mentions": total_mentions,
        "chart_data": chart_data
    }

def get_phase_position(phase):
    """Posiciones en la curva del Hype Cycle"""
    positions = {
        "Pre-Innovation Trigger": {"x": 5, "y": 10},
        "Innovation Trigger": {"x": 15, "y": 30},
        "Peak of Inflated Expectations": {"x": 30, "y": 85},
        "Trough of Disillusionment": {"x": 55, "y": 20},
        "Slope of Enlightenment": {"x": 75, "y": 50},
        "Plateau of Productivity": {"x": 90, "y": 65}
    }
    return positions.get(phase, {"x": 50, "y": 50})

def generate_insights(hype_data):
    """Genera insights bÃ¡sicos"""
    phase = hype_data["phase"]
    confidence = hype_data["confidence"]
    total_mentions = hype_data["total_mentions"]
    
    insights = []
    
    if phase == "Innovation Trigger":
        insights.append("ðŸš€ TecnologÃ­a emergente con potencial de crecimiento")
        insights.append("âš ï¸ Alto riesgo - Pocos casos de uso demostrados")
    elif phase == "Peak of Inflated Expectations":
        insights.append("ðŸ“ˆ MÃ¡ximo nivel de expectativas en medios")
        insights.append("â³ Probable declive en prÃ³ximos 2-3 aÃ±os")
    elif phase == "Trough of Disillusionment":
        insights.append("ðŸ“‰ Fase de desilusiÃ³n - Expectativas mÃ¡s realistas")
        insights.append("ðŸ’¡ Buen momento para inversiÃ³n a largo plazo")
    elif phase == "Slope of Enlightenment":
        insights.append("ðŸ“Š MaduraciÃ³n gradual de la tecnologÃ­a")
        insights.append("âœ… Casos de uso mÃ¡s claros y beneficios demostrados")
    elif phase == "Plateau of Productivity":
        insights.append("ðŸ† TecnologÃ­a madura y ampliamente adoptada")
        insights.append("ðŸ’¼ ROI demostrado y riesgos controlados")
    
    if confidence > 0.7:
        insights.append("âœ… Alta confianza en el anÃ¡lisis")
    elif confidence < 0.5:
        insights.append("âš ï¸ Confianza limitada - Se requieren mÃ¡s datos")
    
    insights.append(f"ðŸ“Š Total de menciones analizadas: {total_mentions}")
    
    return insights

@app.post("/api/hypecycle/analyze", response_model=HypeCycleResponse)
async def analyze_hypecycle(request: HypeCycleRequest):
    serp_api_key = os.getenv("SERP_API_KEY")
    
    if not serp_api_key:
        raise HTTPException(status_code=500, detail="SERP_API_KEY no configurada")
    
    # Construir query
    google_query = build_google_query(request.search_terms, request.min_year)
    
    if not google_query:
        raise HTTPException(status_code=400, detail="Query vacÃ­a")
    
    print(f"Searching for: {google_query}")  # Debug
    
    # Realizar bÃºsqueda
    success, results = perform_news_search(google_query, serp_api_key)
    
    if not success:
        raise HTTPException(status_code=400, detail=f"Error en bÃºsqueda: {results}")
    
    print(f"Found {len(results) if isinstance(results, list) else 0} results")  # Debug
    
    # Analizar Hype Cycle
    hype_data = analyze_hype_cycle(results)
    
    if not hype_data:
        raise HTTPException(status_code=400, detail="No se pudieron procesar los resultados")
    
    # Generar insights
    insights = generate_insights(hype_data)
    
    return HypeCycleResponse(
        success=True,
        phase=hype_data["phase"],
        confidence=hype_data["confidence"],
        total_mentions=hype_data["total_mentions"],
        insights=insights,
        chart_data=hype_data["chart_data"]
    )

@app.get("/api/health")
async def health_check():
    return {"status": "healthy", "message": "CycleAI Backend is running"}

# âœ… Endpoint de prueba sin API key
@app.get("/api/test")
async def test_endpoint():
    return {
        "success": True,
        "phase": "Innovation Trigger",
        "confidence": 0.75,
        "total_mentions": 42,
        "insights": [
            "ðŸš€ TecnologÃ­a emergente con potencial de crecimiento",
            "âš ï¸ Alto riesgo - Pocos casos de uso demostrados",
            "ðŸ“Š Total de menciones analizadas: 42"
        ],
        "chart_data": {
            "yearly_mentions": {"2020": 5, "2021": 12, "2022": 15, "2023": 10},
            "phase_position": {"x": 15, "y": 30},
            "total_mentions": 42
        }
    }